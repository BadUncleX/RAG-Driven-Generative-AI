# RAG-driven Generative AI
by Denis Rothman <br><br>
<img src="https://github.com/Denis2054/RAG-Driven-Generative-AI/blob/main/rag.png?raw=tru" alt="drawing" width="400"/>

Last updated: March 29, 2024  
Look for the  üê¨ for bonus notebooks! 

# Transformers-for-NLP-and-Computer-Vision-3rd-Edition
This is the code repository for [Transformers for Natural Language Processing and Computer Vision](https://www.amazon.com/Transformers-Natural-Language-Processing-Computer/dp/1805128728/), published by Packt.

**Explore Generative AI and Large Language Models with Hugging Face, ChatGPT, GPT-4V, and DALL-E 3**

## About the book
Transformers for Natural Language Processing and Computer Vision, Third Edition, explores **Large Language Model** (**LLM**) architectures, applications, and various platforms (Hugging Face, OpenAI, and Google Vertex AI) used for **Natural Language Processing** (**NLP**) and **Computer Vision** (**CV**).

Dive into generative vision transformers and multimodal model architectures and build applications, such as image and video-to-text classifiers. Go further by combining different models and platforms and learning about AI agent replication.

## What you will learn
- Learn how to pretrain and fine-tune LLMs
- Learn how to work with multiple platforms, such as Hugging Face, OpenAI, and Google Vertex AI
- Learn about different tokenizers and the best practices for preprocessing language data
- Implement Retrieval Augmented Generation and rules bases to mitigate hallucinations
- Visualize transformer model activity for deeper insights using BertViz, LIME, and SHAP
- Create and implement cross-platform chained models, such as HuggingGPT
- Go in-depth into vision transformers with CLIP, DALL-E 2, DALL-E 3, and GPT-4V


## Table of Contents
### Chapters
1. What Are Transformers?
2. Getting Started with the Architecture of the Transformer Model
3. Emergent vs Downstream Tasks: The Unseen Depths of Transformers
4. Advancements in Translations with Google Trax, Google Translate, and Gemini
5. Diving into Fine-Tuning through BERT
6. Pretraining a Transformer from Scratch through RoBERTa
7. The Generative AI Revolution with ChatGPT
8. Fine-Tuning OpenAI GPT Models
9. Shattering the Black Box with Interpretable Tools
10. Investigating the Role of Tokenizers in Shaping Transformer Models 
11. Leveraging LLM Embeddings as an Alternative to Fine-Tuning
12. Toward Syntax-Free Semantic Role Labeling with ChatGPT and GPT-4
13. Summarization with T5 and ChatGPT
14. Exploring Cutting-Edge LLMs with Vertex AI and PaLM 2
15. Guarding the Giants: Mitigating Risks in Large Language Models
16. Beyond Text: Vision Transformers in the Dawn of Revolutionary AI
17. Transcending the Image-Text Boundary with Stable Diffusion
18. Hugging Face AutoTrain: Training Vision Models without Coding
19. On the Road to Functional AGI with HuggingGPT and its Peers
20. Beyond Human-Designed Prompts with Generative Ideation
### Appendix
Appendix: Answers to the Questions


### Platforms
You can run the notebooks directly from below table:
| Chapter | Colab | Kaggle | Gradient | StudioLab |
| :-------- | :-------- | :------- |:------- |:------- |
| | | | | |
**Part I The Foundations of Transformer Models**
 **Chapter 1: What are Transformers?**
| <ul><li>O_1_and_Accelerators.ipynb</li><li>ChatGPT_Plus_writes_and_explains_AI.ipynb</li></ul> |[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter01/O_1_and_Accelerators.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter01/ChatGPT_Plus_writes_and_explains_AI.ipynb) | [![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter01/O_1_and_Accelerators.ipynb) [![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter01/ChatGPT_Plus_writes_and_explains_AI.ipynb) | [![Gradient](https://assets.paperspace.io/img/gradient-badge.svg)](https://console.paperspace.com/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter01/O_1_and_Accelerators.ipynb?file=%2FChapter01%2FO_1_and_Accelerators.ipynb) [![Gradient](https://assets.paperspace.io/img/gradient-badge.svg)](https://console.paperspace.com/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter01/ChatGPT_Plus_writes_and_explains_AI.ipynb?file=%2FChapter01%2FChatGPT_Plus_writes_and_explains_AI.ipynb) | [![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter01/O_1_and_Accelerators.ipynb)	[![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter01/ChatGPT_Plus_writes_and_explains_AI.ipynb) |
 **Chapter 2: Getting Started with the Architecture of the Transformer Model**
| <ul><li>Multi_Head_Attention_Sub_Layer.ipynb</li><li>positional_encoding.ipynb</li></ul> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter02/Multi_Head_Attention_Sub_Layer.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter02/positional_encoding.ipynb) | [![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter02/Multi_Head_Attention_Sub_Layer.ipynb) [![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter02/positional_encoding.ipynb) | [![Gradient](https://assets.paperspace.io/img/gradient-badge.svg)](https://console.paperspace.com/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter02/Multi_Head_Attention_Sub_Layer.ipynb?file=%2FChapter02%2FMulti_Head_Attention_Sub_Layer.ipynb) [![Gradient](https://assets.paperspace.io/img/gradient-badge.svg)](https://console.paperspace.com/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter02/positional_encoding.ipynb?file=%2FChapter02%2Fpositional_encoding.ipynb) | [![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter02/Multi_Head_Attention_Sub_Layer.ipynb) [![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/blob/main/Chapter02/positional_encoding.ipynb) |

## Get to Know the Author
Denis Rothman graduated from Sorbonne University and Paris Diderot University, designing one of the first patented encoding and embedding systems. He authored one of the first patented AI cognitive robots and bots. He began his career delivering Natural Language Processing (NLP) chatbots for Mo√´t et Chandon and as an AI tactical defense optimizer for Airbus (formerly Aerospatiale).
Denis then authored an AI resource optimizer for IBM and luxury brands, leading to an Advanced Planning and Scheduling (APS) solution used worldwide.
[LinkedIn](https://www.linkedin.com/in/denis-rothman-0b034043/)
