{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "QE7BlcRs_VTr"
      ],
      "mount_file_id": "1gjwqoCHDA5wr3y_66gIPBkxwyD5CPYlj",
      "authorship_tag": "ABX9TyMdreg64Lzx1uebtyoLQkiH"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Embedding-Based Retrieval with Activeloop and OpenAI\n",
        "\n",
        "Copyright 2024 Denis Rothman\n",
        "\n"
      ],
      "metadata": {
        "id": "YMfhL3l9Nj-S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Installing the environment"
      ],
      "metadata": {
        "id": "QE7BlcRs_VTr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount a drive or implement the method that best fits your project to retrieve API tokens."
      ],
      "metadata": {
        "id": "LLbqFmIh91as"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Google Drive option to store API Keys\n",
        "#Store you key in a file and read it(you can type it directly in the notebook but it will be visible for somebody next to you)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pu-obY57BKtV",
        "outputId": "65818030-7473-401b-a0b7-7a0959f61079"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "grequests.py contains a function to download files from GitHub"
      ],
      "metadata": {
        "id": "Em5tYCqISmRz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#GitHub grequests.py\n",
        "#Script to download files from the GitHub repository.\n",
        "#The private token will be removed from this function when the repository goes public.\n",
        "\n",
        "import subprocess\n",
        "\n",
        "# Define your private token as a variable\n",
        "private_token='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'\n",
        "url = \"https://raw.githubusercontent.com/Denis2054/RAG-Driven-Generative-AI/main/commons/grequests.py\"\n",
        "output_file = \"grequests.py\"\n",
        "\n",
        "# Prepare the curl command using the private token\n",
        "curl_command = [\n",
        "    \"curl\",\n",
        "    \"-H\", f\"Authorization: token {private_token}\",\n",
        "    \"-o\", output_file,\n",
        "    url\n",
        "]\n",
        "\n",
        "# Execute the curl command\n",
        "try:\n",
        "    subprocess.run(curl_command, check=True)\n",
        "    print(\"Download successful.\")\n",
        "except subprocess.CalledProcessError:\n",
        "    print(\"Failed to download the file.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxqIxsO674vx",
        "outputId": "dcf09468-82c1-4256-d8cf-2a31dedddb5f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download successful.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### List of Dependencies for `deeplake`:\n",
        "\n",
        "deeplake==3.9.2 has a main package and a list of dependencies:\n",
        "\n",
        "- **deeplake (3.9.2)**: Main package being installed.\n",
        "- **numpy (1.25.2)**: Required for numerical operations within deeplake.\n",
        "- **pillow (10.2.0)**: Used for image manipulation and processing.\n",
        "- **boto3 (1.34.69)**: Amazon Web Services (AWS) SDK for Python, used for working with AWS services.\n",
        "- **pathos (0.3.2)**: Provides utilities for parallel processing.\n",
        "- **humbug (0.3.2)**: Reporting tool for bugs and usage metrics.\n",
        "- **lz4 (4.3.3)**: Provides LZ4 compression for fast data packing.\n",
        "- **pyjwt (2.3.0)**: Allows for encoding, decoding, and verification of JWTs.\n",
        "- **pydantic (2.7.1)**: Data validation by using Python type hints.\n",
        "- **libdeeplake (0.0.123)**: Likely a core library for deeplake's functionalities.\n",
        "- **aioboto3 (12.4.0)**: Asynchronous SDK for AWS services, allowing non-blocking AWS operations.\n",
        "- **dill (0.3.8)**: Extends python’s `pickle` module for serializing and deserializing python objects.\n",
        "- **aiobotocore (2.12.3)**: Core component of aioboto3, providing low-level interface to AWS services asynchronously.\n",
        "- **aioitertools (0.11.0)**: Tools and helper functions to make async iterations easy.\n",
        "- **botocore (1.34.69)**: Low-level interface to AWS, used by boto3 and aiobotocore.\n",
        "- **jmespath (1.0.1)**: Allows declarative JSON querying.\n",
        "- **s3transfer (0.10.1)**: Amazon S3 Transfer Manager for boto3.\n",
        "- **ppft (1.7.6.8)**, **pox (0.3.4)**, **multiprocess (0.70.16)**: Components of pathos, handling parallel processing infrastructure.\n",
        "\n",
        "### May 3, 2024: Explanation of Pillow Version Requirement which causes a conflict with Google Colab until Google Colab upgrades Pillow:\n",
        "\n",
        "**Pillow (10.2.0)** is specified in the deeplake dependencies as `pillow~=10.2.0`. This version specifier means that deeplake requires a version of Pillow that is compatible with 10.2.0. The tilde equals (`~=`) is a version specifier that matches the most recent version that is compatible with the specified version, meaning it allows versions that are the same as 10.2.x where x is equal to or greater than 0, but less than the next significant release which would be 10.3.\n",
        "\n",
        "This specific version constraint ensures that deeplake uses features or functionalities that are present only in the Pillow 10.2.x releases. If Pillow were to be updated beyond this range, it could potentially introduce breaking changes that deeplake may not be compatible with, or it could remove features that deeplake relies on. The constraint thereby protects the application from unexpected behavior or errors due to incompatible library versions."
      ],
      "metadata": {
        "id": "PCGLsxRSRKDj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "checking to see if Google Colab has the right version Pillow. If not, Pillow is uninstalled and a version compatiable with DeepLake is installed."
      ],
      "metadata": {
        "id": "Vuy34xA4TfUS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "import subprocess\n",
        "\n",
        "# Check current version of Pillow\n",
        "current_version = PIL.__version__\n",
        "\n",
        "# Define the required version\n",
        "required_version = \"10.2.0\"\n",
        "\n",
        "# Function to parse version strings\n",
        "def version_tuple(version):\n",
        "    return tuple(map(int, (version.split(\".\"))))\n",
        "\n",
        "# Compare current and required version\n",
        "if version_tuple(current_version) < version_tuple(required_version):\n",
        "    print(f\"Current Pillow version {current_version} is less than {required_version}. Updating...\")\n",
        "    # Uninstall current version of Pillow\n",
        "    subprocess.run(['pip', 'uninstall', 'pillow', '-y'])\n",
        "    # Install the required version of Pillow\n",
        "    subprocess.run(['pip', 'install', f'pillow=={required_version}'])\n",
        "else:\n",
        "    print(f\"Current Pillow version {current_version} meets the requirement.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIOJiqruRDsX",
        "outputId": "201cfe0d-1d3c-4e89-92ec-0f8a4b657ff3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Pillow version 9.4.0 is less than 10.2.0. Updating...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deeplake==3.9.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_VA6VANdsZM",
        "outputId": "162f7a87-fa32-462f-ec27-24ebe223bdac"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deeplake==3.9.2\n",
            "  Downloading deeplake-3.9.2.tar.gz (590 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/590.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/590.0 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m501.8/590.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.0/590.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deeplake==3.9.2) (1.25.2)\n",
            "Requirement already satisfied: pillow~=10.2.0 in /usr/local/lib/python3.10/dist-packages (from deeplake==3.9.2) (10.2.0)\n",
            "Collecting boto3 (from deeplake==3.9.2)\n",
            "  Downloading boto3-1.34.96-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from deeplake==3.9.2) (8.1.7)\n",
            "Collecting pathos (from deeplake==3.9.2)\n",
            "  Downloading pathos-0.3.2-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting humbug>=0.3.1 (from deeplake==3.9.2)\n",
            "  Downloading humbug-0.3.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from deeplake==3.9.2) (4.66.2)\n",
            "Collecting lz4 (from deeplake==3.9.2)\n",
            "  Downloading lz4-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyjwt in /usr/lib/python3/dist-packages (from deeplake==3.9.2) (2.3.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from deeplake==3.9.2) (2.7.1)\n",
            "Collecting libdeeplake==0.0.123 (from deeplake==3.9.2)\n",
            "  Downloading libdeeplake-0.0.123-cp310-cp310-manylinux_2_28_x86_64.whl (16.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aioboto3>=10.4.0 (from deeplake==3.9.2)\n",
            "  Downloading aioboto3-12.4.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from deeplake==3.9.2) (1.6.0)\n",
            "Collecting dill (from libdeeplake==0.0.123->deeplake==3.9.2)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiobotocore[boto3]==2.12.3 (from aioboto3>=10.4.0->deeplake==3.9.2)\n",
            "  Downloading aiobotocore-2.12.3-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting botocore<1.34.70,>=1.34.41 (from aiobotocore[boto3]==2.12.3->aioboto3>=10.4.0->deeplake==3.9.2)\n",
            "  Downloading botocore-1.34.69-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp<4.0.0,>=3.7.4.post0 in /usr/local/lib/python3.10/dist-packages (from aiobotocore[boto3]==2.12.3->aioboto3>=10.4.0->deeplake==3.9.2) (3.9.5)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.10.10 in /usr/local/lib/python3.10/dist-packages (from aiobotocore[boto3]==2.12.3->aioboto3>=10.4.0->deeplake==3.9.2) (1.14.1)\n",
            "Collecting aioitertools<1.0.0,>=0.5.1 (from aiobotocore[boto3]==2.12.3->aioboto3>=10.4.0->deeplake==3.9.2)\n",
            "  Downloading aioitertools-0.11.0-py3-none-any.whl (23 kB)\n",
            "Collecting boto3 (from deeplake==3.9.2)\n",
            "  Downloading boto3-1.34.69-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3->deeplake==3.9.2)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3->deeplake==3.9.2)\n",
            "  Downloading s3transfer-0.10.1-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from humbug>=0.3.1->deeplake==3.9.2) (2.31.0)\n",
            "Collecting ppft>=1.7.6.8 (from pathos->deeplake==3.9.2)\n",
            "  Downloading ppft-1.7.6.8-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pox>=0.3.4 (from pathos->deeplake==3.9.2)\n",
            "  Downloading pox-0.3.4-py3-none-any.whl (29 kB)\n",
            "Collecting multiprocess>=0.70.16 (from pathos->deeplake==3.9.2)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->deeplake==3.9.2) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic->deeplake==3.9.2) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic->deeplake==3.9.2) (4.11.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.34.70,>=1.34.41->aiobotocore[boto3]==2.12.3->aioboto3>=10.4.0->deeplake==3.9.2) (2.8.2)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.34.70,>=1.34.41->aiobotocore[boto3]==2.12.3->aioboto3>=10.4.0->deeplake==3.9.2) (2.0.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->humbug>=0.3.1->deeplake==3.9.2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->humbug>=0.3.1->deeplake==3.9.2) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->humbug>=0.3.1->deeplake==3.9.2) (2024.2.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.7.4.post0->aiobotocore[boto3]==2.12.3->aioboto3>=10.4.0->deeplake==3.9.2) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.7.4.post0->aiobotocore[boto3]==2.12.3->aioboto3>=10.4.0->deeplake==3.9.2) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.7.4.post0->aiobotocore[boto3]==2.12.3->aioboto3>=10.4.0->deeplake==3.9.2) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.7.4.post0->aiobotocore[boto3]==2.12.3->aioboto3>=10.4.0->deeplake==3.9.2) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.7.4.post0->aiobotocore[boto3]==2.12.3->aioboto3>=10.4.0->deeplake==3.9.2) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.7.4.post0->aiobotocore[boto3]==2.12.3->aioboto3>=10.4.0->deeplake==3.9.2) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.34.70,>=1.34.41->aiobotocore[boto3]==2.12.3->aioboto3>=10.4.0->deeplake==3.9.2) (1.16.0)\n",
            "Building wheels for collected packages: deeplake\n",
            "  Building wheel for deeplake (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deeplake: filename=deeplake-3.9.2-py3-none-any.whl size=711851 sha256=a85a5777adfef45711a7248702fdf58f837e53544a1e38fe01592e530cedfa91\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/27/d1/8177a0262ec158732d8cf2ab7c179375020d02f9bb4e0d42c1\n",
            "Successfully built deeplake\n",
            "Installing collected packages: ppft, pox, lz4, jmespath, dill, aioitertools, multiprocess, libdeeplake, humbug, botocore, s3transfer, pathos, aiobotocore, boto3, aioboto3, deeplake\n",
            "Successfully installed aioboto3-12.4.0 aiobotocore-2.12.3 aioitertools-0.11.0 boto3-1.34.69 botocore-1.34.69 deeplake-3.9.2 dill-0.3.8 humbug-0.3.2 jmespath-1.0.1 libdeeplake-0.0.123 lz4-4.3.3 multiprocess-0.70.16 pathos-0.3.2 pox-0.3.4 ppft-1.7.6.8 s3transfer-0.10.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==1.25.0"
      ],
      "metadata": {
        "id": "Rn9TVha_a7q2",
        "outputId": "32112e94-7bb3-44e1-fa5c-26fc2187d048",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==1.25.0\n",
            "  Downloading openai-1.25.0-py3-none-any.whl (312 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.9/312.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.25.0) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai==1.25.0) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai==1.25.0)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.25.0) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai==1.25.0) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai==1.25.0) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai==1.25.0) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.25.0) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.25.0) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.25.0) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai==1.25.0)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.25.0)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.25.0) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.25.0) (2.18.2)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.25.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For Google Colab and Activeloop while waiting for Activeloop (April 2024) pending new version\n",
        "#This line writes the string \"nameserver 8.8.8.8\" to the file. This is specifying that the DNS server the system\n",
        "#should use is at the IP address 8.8.8.8, which is one of Google's Public DNS servers.\n",
        "with open('/etc/resolv.conf', 'w') as file:\n",
        "   file.write(\"nameserver 8.8.8.8\")"
      ],
      "metadata": {
        "id": "vv0TB4Q8fCfT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Retrieving and setting the OpenAI API key\n",
        "f = open(\"drive/MyDrive/files/api_key.txt\", \"r\")\n",
        "API_KEY=f.readline()\n",
        "f.close()\n",
        "\n",
        "#The OpenAI KeyActiveloop and OpenAI API keys\n",
        "import os\n",
        "import openai\n",
        "os.environ['OPENAI_API_KEY'] =API_KEY\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "Oefvqp21Ba07"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Retrieving and setting the Activeloop API token\n",
        "f = open(\"drive/MyDrive/files/activeloop.txt\", \"r\")\n",
        "API_token=f.readline()\n",
        "f.close()\n",
        "ACTIVELOOP_TOKEN=API_token\n",
        "os.environ['ACTIVELOOP_TOKEN'] =ACTIVELOOP_TOKEN"
      ],
      "metadata": {
        "id": "Iba6wGaaBgPQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retrieval Augmented Generation"
      ],
      "metadata": {
        "id": "mbSAgh90-Gvu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initiating the query process"
      ],
      "metadata": {
        "id": "LEgp9ruS-YXB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store_path = \"hub://denis76/space_exploration_v4\""
      ],
      "metadata": {
        "id": "rT7DXpFf-YXL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from deeplake.core.vectorstore.deeplake_vectorstore import VectorStore\n",
        "import deeplake.util\n",
        "ds = deeplake.load(vector_store_path)"
      ],
      "metadata": {
        "id": "DD3AYI-o-YXL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be5d3bfa-2f65-4df0-d61f-62e108560c0e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/denis76/space_exploration_v4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "|"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hub://denis76/space_exploration_v4 loaded successfully.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r \r\r\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store = VectorStore(path=vector_store_path)\n",
        "print(\"Vector store exists\")"
      ],
      "metadata": {
        "id": "1-YRhgXiUWjs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6828d53-bf32-413d-fb65-0a88e72a7472"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deep Lake Dataset in hub://denis76/space_exploration_v4 already exists, loading from the storage\n",
            "Vector store exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Input and Query Retrieval"
      ],
      "metadata": {
        "id": "pfX3Y7iIjZUK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Input"
      ],
      "metadata": {
        "id": "J1Qx6ZGgJ20x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retrieval query"
      ],
      "metadata": {
        "id": "S7SqWk-D14Hx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "the embedding function"
      ],
      "metadata": {
        "id": "dVitM_ndtkVU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def embedding_function(texts, model=\"text-embedding-ada-002\"):\n",
        "   if isinstance(texts, str):\n",
        "       texts = [texts]\n",
        "   texts = [t.replace(\"\\n\", \" \") for t in texts]\n",
        "   return [data.embedding for data in openai.embeddings.create(input = texts, model=model).data]"
      ],
      "metadata": {
        "id": "8FPjLp7QVFtr"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "the user prompt"
      ],
      "metadata": {
        "id": "pBKtWki0tm9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_user_prompt():\n",
        "    # Request user input for the search prompt\n",
        "    return input(\"Enter your search query: \")\n",
        "\n",
        "# Get the user's search query\n",
        "#user_prompt = get_user_prompt()\n",
        "user_prompt=\"Tell me about space exploration on the Moon.\""
      ],
      "metadata": {
        "id": "GdiOnfdmmmBm"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "search and store the result in `search_results`"
      ],
      "metadata": {
        "id": "KDIStp86tzsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "search_results = vector_store.search(embedding_data=user_prompt, embedding_function=embedding_function)"
      ],
      "metadata": {
        "id": "yzjLGdgCqfGX"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "displaying the user prompt and the formatted response"
      ],
      "metadata": {
        "id": "9AYBWQjit-OJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(user_prompt)"
      ],
      "metadata": {
        "id": "-fC2yn2PQr3I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "344abdc1-f580-46f3-aee5-e48c426afaf4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tell me about space exploration on the Moon.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to wrap text to a specified width\n",
        "def wrap_text(text, width=80):\n",
        "    lines = []\n",
        "    while len(text) > width:\n",
        "        split_index = text.rfind(' ', 0, width)\n",
        "        if split_index == -1:\n",
        "            split_index = width\n",
        "        lines.append(text[:split_index])\n",
        "        text = text[split_index:].strip()\n",
        "    lines.append(text)\n",
        "    return '\\n'.join(lines)"
      ],
      "metadata": {
        "id": "vU3LSjr_mQHW"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "\n",
        "# Assuming the search results are ordered with the top result first\n",
        "top_score = search_results['score'][0]\n",
        "top_text = search_results['text'][0].strip()\n",
        "top_metadata = search_results['metadata'][0]['source']\n",
        "\n",
        "# Print the top search result\n",
        "print(\"Top Search Result:\")\n",
        "print(f\"Score: {top_score}\")\n",
        "print(f\"Source: {top_metadata}\")\n",
        "print(\"Text:\")\n",
        "print(wrap_text(top_text))"
      ],
      "metadata": {
        "id": "rGsQPjOsQeWE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a3493d6-b05e-4f11-b1d1-a770fd10a565"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top Search Result:\n",
            "Score: 0.8819366693496704\n",
            "Source: llm.txt\n",
            "Text:\n",
            "Exploration of space, planets, and moons \"Space Exploration\" redirects here.\n",
            "For the company, see SpaceX . For broader coverage of this topic, see\n",
            "Exploration . Buzz Aldrin taking a core sample of the Moon during the Apollo 11\n",
            "mission Self-portrait of Curiosity rover on Mars 's surface Part of a series on\n",
            "Spaceflight History History of spaceflight Space Race Timeline of spaceflight\n",
            "Space probes Lunar missions Mars missions Applications Communications Earth\n",
            "observation Exploration Espionage Military Navigation Settlement Telescopes\n",
            "Tourism Spacecraft Robotic spacecraft Satellite Space probe Cargo spacecraft\n",
            "Crewed spacecraft Apollo Lunar Module Space capsules Space Shuttle Space\n",
            "stations Spaceplanes Vostok Space launch Spaceport Launch pad Expendable and\n",
            "reusable launch vehicles Escape velocity Non-rocket spacelaunch Spaceflight\n",
            "types Sub-orbital Orbital Interplanetary Interstellar Intergalactic List of\n",
            "space organizations Space agencies Space forces Companies Spaceflight portal v\n",
            "t e S\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Augmented Input"
      ],
      "metadata": {
        "id": "RWi0gOUnkSi4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "augmented_input=user_prompt+\" \"+top_text"
      ],
      "metadata": {
        "id": "ZX7tEEDWRD3r"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(augmented_input)"
      ],
      "metadata": {
        "id": "ASwAjnecRORo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d113da7b-8993-48a8-bc32-64db189d78b9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tell me about space exploration on the Moon. Exploration of space, planets, and moons \"Space Exploration\" redirects here. For the company, see SpaceX . For broader coverage of this topic, see Exploration . Buzz Aldrin taking a core sample of the Moon during the Apollo 11 mission Self-portrait of Curiosity rover on Mars 's surface Part of a series on Spaceflight History History of spaceflight Space Race Timeline of spaceflight Space probes Lunar missions Mars missions Applications Communications Earth observation Exploration Espionage Military Navigation Settlement Telescopes Tourism Spacecraft Robotic spacecraft Satellite Space probe Cargo spacecraft Crewed spacecraft Apollo Lunar Module Space capsules Space Shuttle Space stations Spaceplanes Vostok Space launch Spaceport Launch pad Expendable and reusable launch vehicles Escape velocity Non-rocket spacelaunch Spaceflight types Sub-orbital Orbital Interplanetary Interstellar Intergalactic List of space organizations Space agencies Space forces Companies Spaceflight portal v t e S\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generation and  output"
      ],
      "metadata": {
        "id": "N8YXkq4QkzJf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "import time\n",
        "\n",
        "\n",
        "gpt_model = \"gpt-4-turbo\"  # or \"gpt-3.5-turbo\"\n",
        "start_time = time.time()  # Start timing before the request\n",
        "\n",
        "def call_gpt4_with_full_text(itext):\n",
        "    # Join all lines to form a single string\n",
        "    text_input = '\\n'.join(itext)\n",
        "    prompt = f\"Please summarize or elaborate on the following content:\\n{text_input}\"\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=gpt_model,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a space exploration expert.\"},\n",
        "                {\"role\": \"assistant\", \"content\": \"You can read the input and answer in detail.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=0.1  # Fine-tune parameters as needed\n",
        "        )\n",
        "        return response.choices[0].message.content.strip()\n",
        "    except Exception as e:\n",
        "        return str(e)\n",
        "\n",
        "gpt4_response = call_gpt4_with_full_text(augmented_input)\n",
        "\n",
        "response_time = time.time() - start_time  # Measure response time\n",
        "print(f\"Response Time: {response_time:.2f} seconds\")  # Print response time\n",
        "\n",
        "print(gpt_model, \"Response:\", gpt4_response)"
      ],
      "metadata": {
        "id": "mIlVfJCyVl_x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf2231bb-73d9-4bc4-9005-f85ffcd0ace5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response Time: 13.01 seconds\n",
            "gpt-4-turbo Response: The text provided discusses various aspects of space exploration, focusing on the exploration of the Moon, planets, and moons in general. It mentions historical events like Buzz Aldrin taking a core sample of the Moon during the Apollo 11 mission and the Curiosity rover's self-portrait on Mars. The content also references broader topics in spaceflight history, including the Space Race and timelines of spaceflight, as well as different types of space missions (lunar, Mars, etc.) and applications such as communications, Earth observation, espionage, military, navigation, settlement, and tourism.\n",
            "\n",
            "Additionally, the text covers various types of spacecraft, including robotic spacecraft, satellites, cargo spacecraft, crewed spacecraft, and specific models like the Apollo Lunar Module, space capsules, space shuttles, and space stations. It also discusses space launch technologies, including launch pads, expendable and reusable launch vehicles, and concepts like escape velocity and non-rocket space launch methods.\n",
            "\n",
            "The text briefly mentions spaceflight types, such as sub-orbital, orbital, interplanetary, interstellar, and intergalactic travel. It also lists space organizations, space agencies, space forces, and companies involved in spaceflight, indicating the broad and multifaceted nature of space exploration endeavors.\n",
            "\n",
            "Overall, the content provides a comprehensive overview of space exploration, highlighting its history, technological advancements, and the wide range of activities and missions undertaken to explore and utilize space.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Formatted response"
      ],
      "metadata": {
        "id": "bVKe9VF0HIHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "\n",
        "def print_formatted_response(response):\n",
        "    # Define the width for wrapping the text\n",
        "    wrapper = textwrap.TextWrapper(width=80)  # Set to 80 columns wide, but adjust as needed\n",
        "    wrapped_text = wrapper.fill(text=response)\n",
        "\n",
        "    # Print the formatted response with a header and footer\n",
        "    print(\"GPT-4 Response:\")\n",
        "    print(\"---------------\")\n",
        "    print(wrapped_text)\n",
        "    print(\"---------------\\n\")\n",
        "\n",
        "# Assuming 'gpt4_response' contains the response from the previous GPT-4 call\n",
        "print_formatted_response(gpt4_response)\n"
      ],
      "metadata": {
        "id": "oG8I2Kb2HFhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating the output with  Cosine Similarity"
      ],
      "metadata": {
        "id": "JtBVjikKmPHt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "with initial user prompt"
      ],
      "metadata": {
        "id": "YM5N5Y70dtgw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def calculate_cosine_similarity(text1, text2):\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf = vectorizer.fit_transform([text1, text2])\n",
        "    similarity = cosine_similarity(tfidf[0:1], tfidf[1:2])\n",
        "    return similarity[0][0]\n",
        "\n",
        "similarity_score = calculate_cosine_similarity(user_prompt, gpt4_response)\n",
        "\n",
        "print(f\"Cosine Similarity Score: {similarity_score:.3f}\")"
      ],
      "metadata": {
        "id": "CieQCTEvHS4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "with augmented user prompt"
      ],
      "metadata": {
        "id": "yWf6gnlgdxC8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "similarity_score = calculate_cosine_similarity(augmented_input, gpt4_response)\n",
        "\n",
        "print(f\"Cosine Similarity Score: {similarity_score:.3f}\")"
      ],
      "metadata": {
        "id": "Hob835ASWzxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install sentence-transformers at the end of this session to avoid potential dependency conflicts with the RAG pipeline requirements."
      ],
      "metadata": {
        "id": "T_ix07EpY2FK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers"
      ],
      "metadata": {
        "id": "Zc67pCDQZEVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "def calculate_cosine_similarity_with_embeddings(text1, text2):\n",
        "    embeddings1 = model.encode(text1)\n",
        "    embeddings2 = model.encode(text2)\n",
        "    similarity = cosine_similarity([embeddings1], [embeddings2])\n",
        "    return similarity[0][0]\n",
        "\n",
        "\n",
        "similarity_score = calculate_cosine_similarity_with_embeddings(augmented_input, gpt4_response)\n",
        "print(f\"Cosine Similarity Score: {similarity_score:.3f}\")"
      ],
      "metadata": {
        "id": "KH4d5jnpY2tN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}