{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMfhL3l9Nj-S"
      },
      "source": [
        "#Embedding-Based Retrieval with Deep Lake and OpenAI\n",
        "\n",
        "Copyright 2024 Denis Rothman\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QE7BlcRs_VTr"
      },
      "source": [
        "# 1. Installing the environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxqIxsO674vx",
        "outputId": "413507f1-8c3e-4bf4-8335-6e2d498f5b26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Download successful.\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "\n",
        "# Define your private token as a variable\n",
        "private_token='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'\n",
        "url = \"https://raw.githubusercontent.com/Denis2054/RAG-Driven-Generative-AI/main/commons/grequests.py\"\n",
        "output_file = \"grequests.py\"\n",
        "\n",
        "# Prepare the curl command using the private token\n",
        "curl_command = [\n",
        "    \"curl\",\n",
        "    \"-H\", f\"Authorization: token {private_token}\",\n",
        "    \"-o\", output_file,\n",
        "    url\n",
        "]\n",
        "\n",
        "# Execute the curl command\n",
        "try:\n",
        "    subprocess.run(curl_command, check=True)\n",
        "    print(\"Download successful.\")\n",
        "except subprocess.CalledProcessError:\n",
        "    print(\"Failed to download the file.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPiVpRYFcV06",
        "outputId": "b43acb29-f83c-4efc-abb8-dd2f47614839"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloaded 'requirements_01.txt' successfully.\n"
          ]
        }
      ],
      "source": [
        "from grequests import download\n",
        "\n",
        "# Define your variables\n",
        "directory = \"commons\"\n",
        "filename = \"requirements_01.txt\"\n",
        "download(directory, filename, private_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "42JrhlSJ-Wr6",
        "outputId": "2114b599-d610-4c7d-d07f-a554b55f4a5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting deeplake==3.6.19 (from -r requirements_01.txt (line 1))\n",
            "  Downloading deeplake-3.6.19.tar.gz (532 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m532.9/532.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting openai==0.28.1 (from -r requirements_01.txt (line 2))\n",
            "  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken==0.4.0 (from -r requirements_01.txt (line 3))\n",
            "  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers==4.32.0 (from -r requirements_01.txt (line 4))\n",
            "  Downloading transformers-4.32.0-py3-none-any.whl (7.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch==2.2.1 (from -r requirements_01.txt (line 5))\n",
            "  Downloading torch-2.2.1-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.24.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements_01.txt (line 6)) (1.25.2)\n",
            "Collecting deepspeed==0.10.1 (from -r requirements_01.txt (line 7))\n",
            "  Downloading deepspeed-0.10.1.tar.gz (851 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m851.5/851.5 kB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting trl==0.7.1 (from -r requirements_01.txt (line 8))\n",
            "  Downloading trl-0.7.1-py3-none-any.whl (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.0/118.0 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting peft==0.5.0 (from -r requirements_01.txt (line 9))\n",
            "  Downloading peft-0.5.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.6/85.6 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wandb==0.15.8 (from -r requirements_01.txt (line 10))\n",
            "  Downloading wandb-0.15.8-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m78.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitsandbytes==0.41.1 (from -r requirements_01.txt (line 11))\n",
            "  Downloading bitsandbytes-0.41.1-py3-none-any.whl (92.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate==0.22.0 (from -r requirements_01.txt (line 12))\n",
            "  Downloading accelerate-0.22.0-py3-none-any.whl (251 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.2/251.2 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm==4.66.1 (from -r requirements_01.txt (line 13))\n",
            "  Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting neural_compressor==2.2.1 (from -r requirements_01.txt (line 14))\n",
            "  Downloading neural_compressor-2.2.1-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnx==1.14.1 (from -r requirements_01.txt (line 15))\n",
            "  Downloading onnx-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas==2.0.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements_01.txt (line 16)) (2.0.3)\n",
            "Collecting scipy==1.11.2 (from -r requirements_01.txt (line 17))\n",
            "  Downloading scipy-1.11.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.3/36.3 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4==4.12.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements_01.txt (line 18)) (4.12.3)\n",
            "Requirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements_01.txt (line 19)) (2.31.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from deeplake==3.6.19->-r requirements_01.txt (line 1)) (9.4.0)\n",
            "Collecting boto3 (from deeplake==3.6.19->-r requirements_01.txt (line 1))\n",
            "  Downloading boto3-1.34.113-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from deeplake==3.6.19->-r requirements_01.txt (line 1)) (8.1.7)\n",
            "Collecting pathos (from deeplake==3.6.19->-r requirements_01.txt (line 1))\n",
            "  Downloading pathos-0.3.2-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting humbug>=0.3.1 (from deeplake==3.6.19->-r requirements_01.txt (line 1))\n",
            "  Downloading humbug-0.3.2-py3-none-any.whl (15 kB)\n",
            "Collecting numcodecs (from deeplake==3.6.19->-r requirements_01.txt (line 1))\n",
            "  Downloading numcodecs-0.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyjwt in /usr/lib/python3/dist-packages (from deeplake==3.6.19->-r requirements_01.txt (line 1)) (2.3.0)\n",
            "Collecting aioboto3>=10.4.0 (from deeplake==3.6.19->-r requirements_01.txt (line 1))\n",
            "  Downloading aioboto3-12.4.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (from deeplake==3.6.19->-r requirements_01.txt (line 1)) (1.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1->-r requirements_01.txt (line 2)) (3.9.5)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.4.0->-r requirements_01.txt (line 3)) (2023.12.25)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.32.0->-r requirements_01.txt (line 4)) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.32.0->-r requirements_01.txt (line 4)) (0.23.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.32.0->-r requirements_01.txt (line 4)) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.32.0->-r requirements_01.txt (line 4)) (6.0.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.32.0->-r requirements_01.txt (line 4))\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.32.0->-r requirements_01.txt (line 4)) (0.4.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->-r requirements_01.txt (line 5)) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->-r requirements_01.txt (line 5)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->-r requirements_01.txt (line 5)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->-r requirements_01.txt (line 5)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->-r requirements_01.txt (line 5)) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.1->-r requirements_01.txt (line 5))\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.1->-r requirements_01.txt (line 5))\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.1->-r requirements_01.txt (line 5))\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.1->-r requirements_01.txt (line 5))\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.1->-r requirements_01.txt (line 5))\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.1->-r requirements_01.txt (line 5))\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.1->-r requirements_01.txt (line 5))\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.1->-r requirements_01.txt (line 5))\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.1->-r requirements_01.txt (line 5))\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.1->-r requirements_01.txt (line 5))\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.1->-r requirements_01.txt (line 5))\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Collecting triton==2.2.0 (from torch==2.2.1->-r requirements_01.txt (line 5))\n",
            "  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hjson (from deepspeed==0.10.1->-r requirements_01.txt (line 7))\n",
            "  Downloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ninja (from deepspeed==0.10.1->-r requirements_01.txt (line 7))\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.10.1->-r requirements_01.txt (line 7)) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.10.1->-r requirements_01.txt (line 7)) (9.0.0)\n",
            "Collecting pydantic<2.0.0 (from deepspeed==0.10.1->-r requirements_01.txt (line 7))\n",
            "  Downloading pydantic-1.10.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets (from trl==0.7.1->-r requirements_01.txt (line 8))\n",
            "  Downloading datasets-2.19.1-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting GitPython!=3.1.29,>=1.0.0 (from wandb==0.15.8->-r requirements_01.txt (line 10))\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentry-sdk>=1.0.0 (from wandb==0.15.8->-r requirements_01.txt (line 10))\n",
            "  Downloading sentry_sdk-2.3.1-py2.py3-none-any.whl (289 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.0/289.0 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb==0.15.8->-r requirements_01.txt (line 10))\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting pathtools (from wandb==0.15.8->-r requirements_01.txt (line 10))\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle (from wandb==0.15.8->-r requirements_01.txt (line 10))\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb==0.15.8->-r requirements_01.txt (line 10)) (67.7.2)\n",
            "Collecting appdirs>=1.4.3 (from wandb==0.15.8->-r requirements_01.txt (line 10))\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.15.8->-r requirements_01.txt (line 10)) (3.20.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from neural_compressor==2.2.1->-r requirements_01.txt (line 14)) (1.2.2)\n",
            "Collecting schema (from neural_compressor==2.2.1->-r requirements_01.txt (line 14))\n",
            "  Downloading schema-0.7.7-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from neural_compressor==2.2.1->-r requirements_01.txt (line 14)) (4.9.0.80)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.10/dist-packages (from neural_compressor==2.2.1->-r requirements_01.txt (line 14)) (3.10.0)\n",
            "Collecting deprecated>=1.2.13 (from neural_compressor==2.2.1->-r requirements_01.txt (line 14))\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from neural_compressor==2.2.1->-r requirements_01.txt (line 14)) (2.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.3->-r requirements_01.txt (line 16)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.3->-r requirements_01.txt (line 16)) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.3->-r requirements_01.txt (line 16)) (2024.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4==4.12.3->-r requirements_01.txt (line 18)) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->-r requirements_01.txt (line 19)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->-r requirements_01.txt (line 19)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->-r requirements_01.txt (line 19)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->-r requirements_01.txt (line 19)) (2024.2.2)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.1->-r requirements_01.txt (line 5))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiobotocore[boto3]==2.12.3 (from aioboto3>=10.4.0->deeplake==3.6.19->-r requirements_01.txt (line 1))\n",
            "  Downloading aiobotocore-2.12.3-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting botocore<1.34.70,>=1.34.41 (from aiobotocore[boto3]==2.12.3->aioboto3>=10.4.0->deeplake==3.6.19->-r requirements_01.txt (line 1))\n",
            "  Downloading botocore-1.34.69-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wrapt<2.0.0,>=1.10.10 in /usr/local/lib/python3.10/dist-packages (from aiobotocore[boto3]==2.12.3->aioboto3>=10.4.0->deeplake==3.6.19->-r requirements_01.txt (line 1)) (1.14.1)\n",
            "Collecting aioitertools<1.0.0,>=0.5.1 (from aiobotocore[boto3]==2.12.3->aioboto3>=10.4.0->deeplake==3.6.19->-r requirements_01.txt (line 1))\n",
            "  Downloading aioitertools-0.11.0-py3-none-any.whl (23 kB)\n",
            "Collecting boto3 (from deeplake==3.6.19->-r requirements_01.txt (line 1))\n",
            "  Downloading boto3-1.34.69-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1->-r requirements_01.txt (line 2)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1->-r requirements_01.txt (line 2)) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1->-r requirements_01.txt (line 2)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1->-r requirements_01.txt (line 2)) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1->-r requirements_01.txt (line 2)) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1->-r requirements_01.txt (line 2)) (4.0.3)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3->deeplake==3.6.19->-r requirements_01.txt (line 1))\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3->deeplake==3.6.19->-r requirements_01.txt (line 1))\n",
            "  Downloading s3transfer-0.10.1-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb==0.15.8->-r requirements_01.txt (line 10)) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb==0.15.8->-r requirements_01.txt (line 10))\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->trl==0.7.1->-r requirements_01.txt (line 8)) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->trl==0.7.1->-r requirements_01.txt (line 8)) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->trl==0.7.1->-r requirements_01.txt (line 8))\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash (from datasets->trl==0.7.1->-r requirements_01.txt (line 8))\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets->trl==0.7.1->-r requirements_01.txt (line 8))\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.1->-r requirements_01.txt (line 5)) (2.1.5)\n",
            "Collecting ppft>=1.7.6.8 (from pathos->deeplake==3.6.19->-r requirements_01.txt (line 1))\n",
            "  Downloading ppft-1.7.6.8-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pox>=0.3.4 (from pathos->deeplake==3.6.19->-r requirements_01.txt (line 1))\n",
            "  Downloading pox-0.3.4-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prettytable->neural_compressor==2.2.1->-r requirements_01.txt (line 14)) (0.2.13)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools->neural_compressor==2.2.1->-r requirements_01.txt (line 14)) (3.7.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->neural_compressor==2.2.1->-r requirements_01.txt (line 14)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->neural_compressor==2.2.1->-r requirements_01.txt (line 14)) (3.5.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.1->-r requirements_01.txt (line 5)) (1.3.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb==0.15.8->-r requirements_01.txt (line 10))\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->neural_compressor==2.2.1->-r requirements_01.txt (line 14)) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->neural_compressor==2.2.1->-r requirements_01.txt (line 14)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->neural_compressor==2.2.1->-r requirements_01.txt (line 14)) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->neural_compressor==2.2.1->-r requirements_01.txt (line 14)) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->neural_compressor==2.2.1->-r requirements_01.txt (line 14)) (3.1.2)\n",
            "Building wheels for collected packages: deeplake, deepspeed, pathtools\n",
            "  Building wheel for deeplake (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deeplake: filename=deeplake-3.6.19-py3-none-any.whl size=647511 sha256=27c29177ada853037d3d27d631c1c733f01340b58e0984bab3653e3d43630635\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/cf/d6/63659e094fe042cd1cb6770d9dba291c5d1af698edc5fb1fe2\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepspeed: filename=deepspeed-0.10.1-py3-none-any.whl size=891667 sha256=9f852e21aacfc5b3ce490e16facfb6af51281772a9fae53b03b788f2dc7fe6a2\n",
            "  Stored in directory: /root/.cache/pip/wheels/fd/5d/48/246fc22e6f69aa948d8f8542f6af89b121dd273bf2c754c049\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=5b30952daf233b4aad83a2da5d5bbefae7173769ff84cc899e948a1895dc92a6\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built deeplake deepspeed pathtools\n",
            "Installing collected packages: tokenizers, schema, pathtools, ninja, hjson, bitsandbytes, appdirs, xxhash, triton, tqdm, smmap, setproctitle, sentry-sdk, scipy, pydantic, ppft, pox, onnx, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numcodecs, jmespath, docker-pycreds, dill, deprecated, aioitertools, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, humbug, gitdb, botocore, transformers, s3transfer, pathos, openai, nvidia-cusolver-cu12, GitPython, aiobotocore, wandb, torch, neural_compressor, datasets, boto3, deepspeed, accelerate, trl, peft, aioboto3, deeplake\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.19.1\n",
            "    Uninstalling tokenizers-0.19.1:\n",
            "      Successfully uninstalled tokenizers-0.19.1\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.3.0\n",
            "    Uninstalling triton-2.3.0:\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements_01.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVEkwfwKQd31"
      },
      "outputs": [],
      "source": [
        "!pip install sentence-transformers==2.7.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vv0TB4Q8fCfT"
      },
      "outputs": [],
      "source": [
        "# For Google Colab and Activeloop while waiting for Activeloop to fix this nameserver issue\n",
        "with open('/etc/resolv.conf', 'w') as file:\n",
        "   file.write(\"nameserver 8.8.8.8\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pu-obY57BKtV"
      },
      "outputs": [],
      "source": [
        "#API Key\n",
        "#Store you key in a file and read it(you can type it directly in the notebook but it will be visible for somebody next to you)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9tyNs0tZbTp"
      },
      "outputs": [],
      "source": [
        "# For Google Colab and Activeloop while waiting for Activeloop to fix this nameserver issue\n",
        "with open('/etc/resolv.conf', 'w') as file:\n",
        "   file.write(\"nameserver 8.8.8.8\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oefvqp21Ba07"
      },
      "outputs": [],
      "source": [
        "f = open(\"drive/MyDrive/files/api_key.txt\", \"r\")\n",
        "API_KEY=f.readline()\n",
        "f.close()\n",
        "\n",
        "#The OpenAI KeyActiveloop and OpenAI API keys\n",
        "import os\n",
        "import openai\n",
        "os.environ['OPENAI_API_KEY'] =API_KEY\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iba6wGaaBgPQ"
      },
      "outputs": [],
      "source": [
        "f = open(\"drive/MyDrive/files/activeloop.txt\", \"r\")\n",
        "API_token=f.readline()\n",
        "f.close()\n",
        "ACTIVELOOP_TOKEN=API_token\n",
        "os.environ['ACTIVELOOP_TOKEN'] =ACTIVELOOP_TOKEN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbSAgh90-Gvu"
      },
      "source": [
        "# Retrieval Augmented Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEgp9ruS-YXB"
      },
      "source": [
        "### Initiating the query process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rT7DXpFf-YXL"
      },
      "outputs": [],
      "source": [
        "vector_store_path = \"hub://denis76/space_exploration_v1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DD3AYI-o-YXL"
      },
      "outputs": [],
      "source": [
        "from deeplake.core.vectorstore.deeplake_vectorstore import VectorStore\n",
        "import deeplake.util\n",
        "ds = deeplake.load(vector_store_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-YRhgXiUWjs"
      },
      "outputs": [],
      "source": [
        "vector_store = VectorStore(path=vector_store_path)\n",
        "print(\"Vector store exists\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfX3Y7iIjZUK"
      },
      "source": [
        "## Input and Query Retrieval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1Qx6ZGgJ20x"
      },
      "source": [
        "## Input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7SqWk-D14Hx"
      },
      "source": [
        "### Retrieval query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FPjLp7QVFtr"
      },
      "outputs": [],
      "source": [
        "def embedding_function(texts, model=\"text-embedding-ada-002\"):\n",
        "\tif isinstance(texts, str):\n",
        "\t\ttexts = [texts]\n",
        "\t\ttexts = [t.replace(\"\\n\", \" \") for t in texts]\n",
        "\t\topenai.Embedding.create\n",
        "\treturn [data['embedding']for data in openai.Embedding.create(input=texts, model=model)['data']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJqzlZqj16yK"
      },
      "outputs": [],
      "source": [
        "def get_user_prompt():\n",
        "    # Request user input for the search prompt\n",
        "    return input(\"Enter your search query: \")\n",
        "\n",
        "def search_query(prompt):\n",
        "    # Assuming `vector_store` and `embedding_function` are already defined\n",
        "    search_results = vector_store.search(embedding_data=prompt, embedding_function=embedding_function)\n",
        "    return search_results\n",
        "\n",
        "# Get the user's search query\n",
        "#user_prompt = get_user_prompt()\n",
        "# or enter prompt if it is in a queue\n",
        "user_prompt=\"Tell me about space exploration on the Moon.\"\n",
        "\n",
        "# Perform the search\n",
        "search_results = search_query(user_prompt)\n",
        "\n",
        "# Print the search results\n",
        "print(search_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fC2yn2PQr3I"
      },
      "outputs": [],
      "source": [
        "print(user_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vU3LSjr_mQHW"
      },
      "outputs": [],
      "source": [
        "# Function to wrap text to a specified width\n",
        "def wrap_text(text, width=80):\n",
        "    lines = []\n",
        "    while len(text) > width:\n",
        "        split_index = text.rfind(' ', 0, width)\n",
        "        if split_index == -1:\n",
        "            split_index = width\n",
        "        lines.append(text[:split_index])\n",
        "        text = text[split_index:].strip()\n",
        "    lines.append(text)\n",
        "    return '\\n'.join(lines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGsQPjOsQeWE"
      },
      "outputs": [],
      "source": [
        "import textwrap\n",
        "\n",
        "# Assuming the search results are ordered with the top result first\n",
        "top_score = search_results['score'][0]\n",
        "top_text = search_results['text'][0].strip()\n",
        "top_metadata = search_results['metadata'][0]['source']\n",
        "\n",
        "# Print the top search result\n",
        "print(\"Top Search Result:\")\n",
        "print(f\"Score: {top_score}\")\n",
        "print(f\"Source: {top_metadata}\")\n",
        "print(\"Text:\")\n",
        "print(wrap_text(top_text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWi0gOUnkSi4"
      },
      "source": [
        "## Augmented Input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZX7tEEDWRD3r"
      },
      "outputs": [],
      "source": [
        "augmented_input=user_prompt+\" \"+top_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASwAjnecRORo"
      },
      "outputs": [],
      "source": [
        "print(augmented_input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8YXkq4QkzJf"
      },
      "source": [
        "# Generation and  output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIlVfJCyVl_x"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import time\n",
        "\n",
        "\n",
        "gpt_model = \"gpt-4-turbo\"  # or \"gpt-3.5-turbo\"\n",
        "start_time = time.time()  # Start timing before the request\n",
        "\n",
        "def call_gpt4_with_full_text(itext):\n",
        "    # Join all lines to form a single string\n",
        "    text_input = '\\n'.join(itext)\n",
        "    prompt = f\"Please summarize or elaborate on the following content:\\n{text_input}\"\n",
        "\n",
        "    try:\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=gpt_model,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a space exploration expert.\"},\n",
        "                {\"role\": \"assistant\", \"content\": \"You can read the input and answer in detail.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=0.1  # Fine-tune parameters as needed\n",
        "        )\n",
        "        return response['choices'][0]['message']['content'].strip()\n",
        "    except Exception as e:\n",
        "        return str(e)\n",
        "\n",
        "gpt4_response = call_gpt4_with_full_text(augmented_input)\n",
        "\n",
        "response_time = time.time() - start_time  # Measure response time\n",
        "print(f\"Response Time: {response_time:.2f} seconds\")  # Print response time\n",
        "\n",
        "print(gpt_model, \"Response:\", gpt4_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVKe9VF0HIHJ"
      },
      "source": [
        "### Formatted response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oG8I2Kb2HFhL"
      },
      "outputs": [],
      "source": [
        "import textwrap\n",
        "\n",
        "def print_formatted_response(response):\n",
        "    # Define the width for wrapping the text\n",
        "    wrapper = textwrap.TextWrapper(width=80)  # Set to 80 columns wide, but adjust as needed\n",
        "    wrapped_text = wrapper.fill(text=response)\n",
        "\n",
        "    # Print the formatted response with a header and footer\n",
        "    print(\"GPT-4 Response:\")\n",
        "    print(\"---------------\")\n",
        "    print(wrapped_text)\n",
        "    print(\"---------------\\n\")\n",
        "\n",
        "# Assuming 'gpt4_response' contains the response from the previous GPT-4 call\n",
        "print_formatted_response(gpt4_response)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtBVjikKmPHt"
      },
      "source": [
        "# Evaluating the output with  Cosine Similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YM5N5Y70dtgw"
      },
      "source": [
        "with initial user prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CieQCTEvHS4L"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def calculate_cosine_similarity(text1, text2):\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf = vectorizer.fit_transform([text1, text2])\n",
        "    similarity = cosine_similarity(tfidf[0:1], tfidf[1:2])\n",
        "    return similarity[0][0]\n",
        "\n",
        "similarity_score = calculate_cosine_similarity(user_prompt, gpt4_response)\n",
        "\n",
        "print(f\"Cosine Similarity Score: {similarity_score:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWf6gnlgdxC8"
      },
      "source": [
        "with augmented user prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hob835ASWzxe"
      },
      "outputs": [],
      "source": [
        "similarity_score = calculate_cosine_similarity(augmented_input, gpt4_response)\n",
        "\n",
        "print(f\"Cosine Similarity Score: {similarity_score:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zc67pCDQZEVR"
      },
      "outputs": [],
      "source": [
        "!pip install sentence-transformers==2.7.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KH4d5jnpY2tN"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "def calculate_cosine_similarity_with_embeddings(text1, text2):\n",
        "    embeddings1 = model.encode(text1)\n",
        "    embeddings2 = model.encode(text2)\n",
        "    similarity = cosine_similarity([embeddings1], [embeddings2])\n",
        "    return similarity[0][0]\n",
        "\n",
        "\n",
        "similarity_score = calculate_cosine_similarity_with_embeddings(augmented_input, gpt4_response)\n",
        "print(f\"Cosine Similarity Score: {similarity_score:.3f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1gjwqoCHDA5wr3y_66gIPBkxwyD5CPYlj",
      "authorship_tag": "ABX9TyMAl/ohV2yhIrjZpNvonPCi"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
